Episode 34: Variation of Parameters for Systems**

Audio Lesson Script**

Welcome to Lesson 34! Today we're extending variation of parameters to systems. So basically, we're solving non-homogeneous systems: x' = Ax + f(t), where f(t) is a forcing term. This is where all our work on homogeneous systems and the matrix exponential pays off big time!

Here's the key insight: just like for single equations, we look for a solution of the form x_p(t) = Φ(t)v(t), where Φ(t) is the fundamental matrix of the homogeneous system, and v(t) is a vector function we need to find. The idea is brilliant - we're varying the constants in the homogeneous solution!

Let me show you the systematic approach. First, recall that the fundamental matrix Φ(t) satisfies:
- Φ'(t) = AΦ(t)
- Φ(0) = I (usually, but we can normalize)

For constant coefficient systems, Φ(t) = e^(At), which we just learned to compute!

Now, assume x_p(t) = Φ(t)v(t). Taking the derivative:
x_p' = Φ'v + Φv' = AΦv + Φv' = Ax_p + Φv'

For this to equal Ax_p + f, we need:
Φv' = f
Therefore: v' = Φ^(-1)f

Integrating: v(t) = ∫Φ^(-1)(s)f(s)ds

So the particular solution is:
**x_p(t) = Φ(t)∫Φ^(-1)(s)f(s)ds**

Let's do a concrete example:
```
x' = [2  1] x + [e^t]
     [0  2]     [0  ]
```

First, find Φ(t). This matrix has repeated eigenvalue λ = 2, so:
Φ(t) = e^(2t)[1  t]
              [0  1]

Next, find Φ^(-1)(t):
Φ^(-1)(t) = e^(-2t)[1  -t]
                    [0   1]

Now compute Φ^(-1)(s)f(s):
Φ^(-1)(s)f(s) = e^(-2s)[1  -s][e^s] = e^(-2s)[e^s] = [e^(-s)]
                        [0   1][0  ]          [0  ]   [0    ]

Integrate:
v(t) = ∫[e^(-s)]ds = [-e^(-s)]|_0^t = [-e^(-t) + 1]
       [0     ]      [0      ]        [0          ]

Finally:
x_p(t) = e^(2t)[1  t][-e^(-t) + 1] = e^(2t)[-e^(-t) + 1]
               [0  1][0          ]          [0          ]
       = [e^t - e^(2t)]
         [0          ]

Wait, let me recalculate that matrix multiplication:
x_p(t) = e^(2t)[1  t][-e^(-t) + 1] = e^(2t)[1(-e^(-t) + 1) + t(0)]
               [0  1][0          ]          [0(-e^(-t) + 1) + 1(0)]
       = e^(2t)[-e^(-t) + 1] = [-e^t + e^(2t)]
               [0          ]    [0            ]

Actually, I made an error. Let me be more careful with the bounds of integration. If we integrate from 0 to t:
v(t) = ∫_0^t [e^(-s)]ds = [-e^(-s)]|_0^t = [-e^(-t) - (-1)] = [1 - e^(-t)]
              [0     ]      [0      ]                          [0         ]

So: x_p(t) = e^(2t)[1  t][1 - e^(-t)] = e^(2t)[1 - e^(-t)]
                    [0  1][0         ]          [0         ]
           = [e^(2t)(1 - e^(-t))] = [e^(2t) - e^t]
             [0                 ]    [0           ]

The general solution is x = x_h + x_p, where x_h is the homogeneous solution.

Here's a crucial observation: for constant coefficient systems, we can write this more elegantly. Since Φ(t) = e^(At) and Φ^(-1)(s) = e^(-As), the particular solution becomes:
**x_p(t) = ∫_0^t e^(A(t-s))f(s)ds**

This is a convolution! It says: "Apply the forcing at time s, then evolve it forward to time t using the homogeneous evolution operator."

Common mistakes to avoid:
1. **Forgetting to find Φ^(-1)** - You need the inverse of the fundamental matrix!
2. **Wrong integration bounds** - Usually integrate from 0 to t
3. **Matrix multiplication errors** - Be super careful with the order
4. **Not checking the solution** - Verify x_p' = Ax_p + f

Prof. Ditkowski loves these types of forcing functions:
- Exponentials: f(t) = [e^(at), 0]^T
- Trigonometric: f(t) = [cos(t), sin(t)]^T
- Polynomials: f(t) = [t, t²]^T
- Step functions: f(t) = [H(t-1), 0]^T

Here's my memory trick: "FIV" - **F**undamental matrix, **I**nverse, **V**ary (integrate).

The physical interpretation is beautiful: each bit of forcing f(s)ds at time s creates an impulse that then evolves according to the homogeneous dynamics. The total response is the superposition of all these evolved impulses - that's what the integral represents!

For the special case where f(t) = e^(αt)b (exponential forcing with constant vector b), if α is not an eigenvalue of A, we can often guess x_p = e^(αt)c and find c algebraically:
αe^(αt)c = Ae^(αt)c + e^(αt)b
(αI - A)c = b
c = (αI - A)^(-1)b

This is much faster than variation of parameters when it works!

Quick exam tip: Prof. Ditkowski often gives you Φ(t) directly to save time, so you just need to find Φ^(-1) and integrate. Also, he loves asking for particular solutions only - you don't always need the complete general solution.

Remember, variation of parameters works for ANY fundamental matrix, not just e^(At). If the system has variable coefficients, you'd use whatever fundamental matrix you can find. But for our course, constant coefficients are the main focus.