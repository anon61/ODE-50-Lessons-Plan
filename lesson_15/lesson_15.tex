\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, amsthm, tikz, pgfplots}
\usepackage{geometry, enumitem, mdframed, array, xcolor}
\geometry{margin=1in}

% Custom environments
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{method}{Method}
\newtheorem{example}{Example}
\newmdenv[linecolor=blue,linewidth=2pt]{keypoint}
\newmdenv[linecolor=red,linewidth=2pt]{warning}
\newmdenv[linecolor=green,linewidth=2pt]{insight}
\newmdenv[linecolor=purple,linewidth=2pt]{examtip}
\newmdenv[linecolor=orange,linewidth=2pt]{formula}

\title{Integrating Factor Technique: Deep Mathematical Analysis}
\author{ODE 1 - Prof. Adi Ditkowski}
\date{Lesson 15}

\begin{document}
\maketitle

\section{The Mathematical Foundation}

The integrating factor technique is more than a computational tool - it represents a fundamental principle in the theory of linear differential equations. This lesson explores the deep mathematical structure underlying this method.

\subsection{The Fundamental Question}

Given a linear first-order ODE:
\begin{equation}
\frac{dy}{dt} + p(t)y = g(t)
\end{equation}

We seek a function $\mu(t)$ such that multiplication transforms the equation into:
\begin{equation}
\frac{d}{dt}[\mu(t)y] = \mu(t)g(t)
\end{equation}

\begin{theorem}[Existence and Uniqueness of Integrating Factor]
For any continuous function $p(t)$ on an interval $I$, there exists a unique (up to scalar multiplication) integrating factor $\mu(t) > 0$ given by:
\begin{equation}
\mu(t) = \exp\left(\int_{t_0}^t p(s)ds\right)
\end{equation}
where $t_0 \in I$ is arbitrary.
\end{theorem}

\begin{proof}
Requiring $\mu(t)y' + \mu(t)p(t)y = \frac{d}{dt}[\mu(t)y] = \mu'(t)y + \mu(t)y'$ yields:
\begin{align}
\mu'(t)y + \mu(t)y' &= \mu(t)y' + \mu(t)p(t)y \\
\mu'(t) &= \mu(t)p(t) \\
\frac{d\mu}{dt} &= p(t)\mu
\end{align}

This is a separable equation with solution:
\begin{equation}
\mu(t) = C\exp\left(\int p(t)dt\right)
\end{equation}

Since any non-zero constant $C$ yields a valid integrating factor, we choose $C = 1$ for simplicity. The uniqueness (up to scalar multiplication) follows from the uniqueness of solutions to the initial value problem $\mu'= p(t)\mu$, $\mu(t_0) = \mu_0$.
\end{proof}

\section{Connection to Exact Differential Equations}

\begin{insight}
The integrating factor transforms a non-exact equation into an exact one. This reveals the deep connection between linear equations and exact equations.
\end{insight}

\begin{proposition}[Exactness After Multiplication]
The equation $\mu(t)[y' + p(t)y - g(t)] = 0$ can be written as:
\begin{equation}
M(t,y)dt + N(t,y)dy = 0
\end{equation}
where $M = \mu(t)[p(t)y - g(t)]$ and $N = \mu(t)$. This equation is exact, meaning:
\begin{equation}
\frac{\partial M}{\partial y} = \frac{\partial N}{\partial t}
\end{equation}
\end{proposition}

\begin{proof}
Computing the partial derivatives:
\begin{align}
\frac{\partial M}{\partial y} &= \mu(t)p(t) \\
\frac{\partial N}{\partial t} &= \mu'(t) = \mu(t)p(t)
\end{align}
The equality follows from the defining property of $\mu(t)$.
\end{proof}

\section{Alternative Forms and Generalizations}

\subsection{Non-Standard Form Integrating Factors}

Consider the general first-order linear equation:
\begin{equation}
a_1(t)y' + a_0(t)y = g(t)
\end{equation}

\begin{method}[Direct Integrating Factor]
Instead of converting to standard form, find $\mu(t)$ such that:
\begin{equation}
\frac{d}{dt}[\mu(t)a_1(t)y] = \mu(t)g(t)
\end{equation}

This requires:
\begin{equation}
\mu(t)a_1(t)y' + [\mu'(t)a_1(t) + \mu(t)a_1'(t)]y = \mu(t)a_1(t)y' + \mu(t)a_0(t)y
\end{equation}

Leading to:
\begin{equation}
\mu'(t) = \mu(t)\left[\frac{a_0(t) - a_1'(t)}{a_1(t)}\right]
\end{equation}
\end{method}

\subsection{Integrating Factors Depending on $y$}

While not applicable to linear equations, for completeness we note that some equations admit integrating factors $\mu(y)$:

\begin{theorem}[Integrating Factor $\mu(y)$]
For the equation $M(t,y)dt + N(t,y)dy = 0$, an integrating factor $\mu(y)$ exists if and only if:
\begin{equation}
\frac{1}{M}\left(\frac{\partial M}{\partial y} - \frac{\partial N}{\partial t}\right) = h(y)
\end{equation}
is a function of $y$ alone. Then $\mu(y) = \exp\left(\int h(y)dy\right)$.
\end{theorem}

\section{The Operator Perspective}

\begin{definition}[Linear Differential Operator]
Define the operator $L: C^1(I) \to C(I)$ by:
\begin{equation}
L[y] = y' + p(t)y
\end{equation}
\end{definition}

\begin{keypoint}
The integrating factor $\mu(t)$ transforms $L$ into the operator $\mu L$, which can be written as:
\begin{equation}
\mu L[y] = \frac{d}{dt}[\mu y]
\end{equation}
This is a composition of multiplication by $\mu$ followed by differentiation.
\end{keypoint}

\subsection{The Adjoint Connection}

\begin{theorem}[Adjoint Operator and Integrating Factor]
The adjoint operator $L^*$ defined by:
\begin{equation}
L^*[v] = -v' + p(t)v
\end{equation}
has the property that $\mu(t)$ satisfies $L^*[\mu] = 0$, making it a solution to the homogeneous adjoint equation.
\end{theorem}

\section{Discontinuous Coefficients}

\begin{warning}
When $p(t)$ has discontinuities, the integrating factor may have different forms on different intervals.
\end{warning}

\begin{example}[Jump Discontinuity]
Consider:
\begin{equation}
y' + p(t)y = 1, \quad p(t) = \begin{cases} 1 & t < 0 \\ 2 & t \geq 0 \end{cases}
\end{equation}

The integrating factor is:
\begin{equation}
\mu(t) = \begin{cases} e^t & t < 0 \\ e^{2t} & t \geq 0 \end{cases}
\end{equation}

Note that $\mu(t)$ has a jump discontinuity at $t = 0$, with $\mu(0^-) = 1$ and $\mu(0^+) = 1$.
\end{example}

\section{Special Integration Techniques}

\subsection{Pattern Recognition}

\begin{formula}
Key patterns for $\int p(t)dt$:
\begin{align}
p(t) = \frac{f'(t)}{f(t)} &\Rightarrow \int p(t)dt = \ln|f(t)| \\
p(t) = \tan(t) &\Rightarrow \int p(t)dt = -\ln|\cos(t)| \\
p(t) = \cot(t) &\Rightarrow \int p(t)dt = \ln|\sin(t)| \\
p(t) = \frac{n}{t} &\Rightarrow \int p(t)dt = n\ln|t|
\end{align}
\end{formula}

\subsection{Reduction Formulas}

For repeated integration by parts situations:

\begin{lemma}[Reduction Formula for $\int t^n e^{at}dt$]
\begin{equation}
\int t^n e^{at}dt = \frac{t^n e^{at}}{a} - \frac{n}{a}\int t^{n-1}e^{at}dt
\end{equation}
\end{lemma}

\section{The Fundamental Solution Connection}

\begin{theorem}[Reciprocal Relationship]
If $y_h(t)$ is a non-zero solution to the homogeneous equation $y' + p(t)y = 0$, then:
\begin{equation}
\mu(t) = \frac{1}{y_h(t)}
\end{equation}
is an integrating factor for the non-homogeneous equation.
\end{theorem}

\begin{proof}
Since $y_h' + p(t)y_h = 0$, we have $y_h'/y_h = -p(t)$. Therefore:
\begin{equation}
y_h = Ce^{-\int p(t)dt} \Rightarrow \frac{1}{y_h} = \frac{1}{C}e^{\int p(t)dt}
\end{equation}
which is indeed an integrating factor (the constant $1/C$ can be absorbed).
\end{proof}

\section{Numerical Stability Considerations}

\begin{examtip}
Prof. Ditkowski may ask about the numerical implications of the integrating factor method.
\end{examtip}

\begin{proposition}[Growth of Integrating Factor]
If $p(t) > 0$ on $[a,b]$, then $\mu(t)$ grows exponentially. If $p(t) < 0$, then $\mu(t)$ decays exponentially. This affects numerical stability:
\begin{itemize}
\item Growing $\mu$: May cause overflow but preserves relative accuracy
\item Decaying $\mu$: May cause underflow and loss of significant digits
\end{itemize}
\end{proposition}

\section{Historical Development}

The integrating factor method was developed by Leonhard Euler in the 18th century. The key insight was recognizing that certain non-exact equations could be made exact through multiplication by an appropriate function.

\begin{keypoint}
Euler's contribution: Transform difficult problems into solvable ones through clever multiplication - a recurring theme in mathematics.
\end{keypoint}

\section{Extension to Systems}

For the system $\mathbf{x}' = A(t)\mathbf{x} + \mathbf{g}(t)$, the integrating factor becomes the matrix exponential or fundamental matrix:

\begin{equation}
\Phi(t) = \exp\left(\int_0^t A(s)ds\right)
\end{equation}

when $A(t)$ commutes with its integral. Otherwise, we need the Peano-Baker series.

\section{Summary: The Complete Picture}

The integrating factor method connects to multiple areas of mathematics:
\begin{itemize}
\item Creates exact differential equations
\item Relates to operator theory and adjoint operators  
\item Connected to fundamental solutions via reciprocal relationship
\item Has numerical stability implications
\item Generalizes to matrix systems
\end{itemize}

\end{document}