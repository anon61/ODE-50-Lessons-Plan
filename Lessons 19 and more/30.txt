# **Lesson 30: Constant Coefficient Systems - Distinct Eigenvalues**

## **Part 1: Audio Lesson Script**

Hey there! Welcome to Lesson 30, where we're diving into one of the most important topics in ODEs - solving systems of linear differential equations with constant coefficients. This is absolutely crucial for Prof. Ditkowski's exam, so let's really nail this down.

So basically, we're looking at systems that look like this: **x' = Ax**, where x is a vector of unknown functions, and A is a constant matrix. Think of it like this - instead of having one differential equation with one unknown function, we now have multiple equations all tangled together. The key insight here is that linear algebra is going to save the day!

Here's the game plan: we're going to find special directions called eigenvectors where the system behaves really simply - just exponential growth or decay. Once we find these special directions and their corresponding growth rates (eigenvalues), we can build the complete solution.

Let me show you the systematic approach. First, we find eigenvalues by solving the characteristic equation: **det(A - λI) = 0**. This gives us a polynomial equation. For a 2×2 matrix, it's a quadratic; for 3×3, it's cubic. The roots of this polynomial are our eigenvalues.

Now here's where students often mess up - after finding eigenvalues, you need to find eigenvectors by solving **(A - λI)v = 0** for EACH eigenvalue separately. This is a homogeneous linear system, and we're looking for non-zero solutions.

Let's work through a concrete 2×2 example. Say we have:
```
x' = [3  1] x
     [1  3]
```

Step 1: Find eigenvalues. The characteristic equation is:
det([3-λ  1  ]) = (3-λ)² - 1 = λ² - 6λ + 8 = 0
   ([1    3-λ])

Factoring: (λ - 4)(λ - 2) = 0, so λ₁ = 4 and λ₂ = 2.

Step 2: Find eigenvectors. For λ₁ = 4:
(A - 4I)v = [-1  1] [v₁] = [0]
            [1  -1] [v₂]   [0]

This gives us -v₁ + v₂ = 0, so v₂ = v₁. Taking v₁ = 1, we get v₁ = [1, 1]ᵀ.

For λ₂ = 2:
(A - 2I)v = [1  1] [v₁] = [0]
            [1  1] [v₂]   [0]

This gives v₁ + v₂ = 0, so v₂ = -v₁. Taking v₁ = 1, we get v₂ = [1, -1]ᵀ.

Step 3: Build the general solution:
**x(t) = c₁e^(4t)[1, 1]ᵀ + c₂e^(2t)[1, -1]ᵀ**

That's it! The solution is a linear combination of exponential solutions along each eigenvector direction.

Now, let's tackle a 3×3 system - these show up on exams too. Consider:
```
x' = [2  1  0]
     [0  2  1] x
     [0  0  3]
```

This is upper triangular, so eigenvalues are just the diagonal entries: λ₁ = 2 (with multiplicity 2) and λ₂ = 3. Wait, that's a repeated eigenvalue! But for this lesson, let's assume we can find enough eigenvectors (we'll handle the defective case in Lesson 31).

Here's a key exam tip: Prof. Ditkowski loves to test whether you can identify the behavior from eigenvalues. If all eigenvalues are negative, solutions decay to zero. If any eigenvalue is positive, you have exponential growth. Mixed signs mean a saddle behavior.

Common mistakes to avoid:
1. **Arithmetic errors** - Double-check your characteristic polynomial!
2. **Wrong eigenvector calculation** - Always verify by computing Av and checking if it equals λv
3. **Forgetting to normalize** - While any scalar multiple works, choosing simple forms helps
4. **Sign errors** - Be super careful with negative eigenvalues

Here's my memory trick for the process: "DAVE" - Determinant (for eigenvalues), Algebra (solve for eigenvectors), Verify (check your work), Exponentials (build the solution).

The physical interpretation is beautiful: each eigenvector defines an invariant direction where solutions just scale exponentially. The eigenvalue tells you the rate. Positive means growth along that direction, negative means decay. The general solution is just a superposition of these basic motions.

For initial value problems, you apply x(0) = x₀ to find the constants. This becomes a linear algebra problem: write x₀ as a linear combination of eigenvectors.

Remember, this distinct eigenvalue case is the "nice" case - it works smoothly because we have enough independent eigenvectors to span the space. Next lesson, we'll see what happens when we don't have enough eigenvectors (repeated eigenvalues with defect), and then we'll handle complex eigenvalues which give us oscillatory behavior.

Practice tip: Start with 2×2 systems until the process is automatic, then move to 3×3. Prof. Ditkowski rarely goes beyond 3×3 on exams, but the process scales to any dimension.

## **Part 2: LaTeX Theory Document**

```latex
\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, amsthm, tikz, pgfplots}
\usepackage{geometry, enumitem, mdframed, array, xcolor}
\usepackage{nicematrix, systeme}
\geometry{margin=1in}

% Custom environments
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{method}{Method}
\newtheorem{example}{Example}
\newmdenv[linecolor=blue,linewidth=2pt]{keypoint}
\newmdenv[linecolor=red,linewidth=2pt]{warning}
\newmdenv[linecolor=green,linewidth=2pt]{insight}
\newmdenv[linecolor=purple,linewidth=2pt]{examtip}
\newmdenv[linecolor=orange,linewidth=2pt]{eigenvalue}

\title{Lesson 30: Constant Coefficient Systems - Distinct Eigenvalues}
\author{ODE 1 - Prof. Adi Ditkowski}
\date{}

\begin{document}
\maketitle

\section{Theory of Linear Systems}

\begin{definition}[Linear System with Constant Coefficients]
A system of linear ODEs with constant coefficients has the form:
\begin{equation}
\mathbf{x}'(t) = A\mathbf{x}(t)
\end{equation}
where $\mathbf{x}(t) = [x_1(t), x_2(t), \ldots, x_n(t)]^T$ and $A$ is an $n \times n$ constant matrix.
\end{definition}

\begin{theorem}[Fundamental Solution Structure]
If $\lambda$ is an eigenvalue of $A$ with eigenvector $\mathbf{v}$, then $\mathbf{x}(t) = e^{\lambda t}\mathbf{v}$ is a solution to $\mathbf{x}' = A\mathbf{x}$.
\end{theorem}

\begin{proof}
Direct verification:
\[\frac{d}{dt}(e^{\lambda t}\mathbf{v}) = \lambda e^{\lambda t}\mathbf{v} = e^{\lambda t}(\lambda \mathbf{v}) = e^{\lambda t}(A\mathbf{v}) = A(e^{\lambda t}\mathbf{v})\]
\end{proof}

\begin{eigenvalue}
\textbf{Eigenvalue Computation Algorithm:}
\begin{enumerate}
\item Form the characteristic polynomial: $p(\lambda) = \det(A - \lambda I)$
\item Expand the determinant (cofactor expansion for $3 \times 3$ or larger)
\item Solve $p(\lambda) = 0$ for eigenvalues $\lambda_1, \lambda_2, \ldots, \lambda_n$
\item For each $\lambda_i$, solve $(A - \lambda_i I)\mathbf{v} = \mathbf{0}$ for eigenvector $\mathbf{v}_i$
\end{enumerate}
\end{eigenvalue}

\begin{theorem}[General Solution for Distinct Eigenvalues]
If $A$ has $n$ distinct eigenvalues $\lambda_1, \ldots, \lambda_n$ with corresponding eigenvectors $\mathbf{v}_1, \ldots, \mathbf{v}_n$, then the general solution is:
\begin{equation}
\mathbf{x}(t) = c_1 e^{\lambda_1 t}\mathbf{v}_1 + c_2 e^{\lambda_2 t}\mathbf{v}_2 + \cdots + c_n e^{\lambda_n t}\mathbf{v}_n
\end{equation}
\end{theorem}

\begin{keypoint}
\textbf{Matrix Diagonalization Perspective:}\\
If $P = [\mathbf{v}_1 | \mathbf{v}_2 | \cdots | \mathbf{v}_n]$ and $D = \text{diag}(\lambda_1, \ldots, \lambda_n)$, then:
\begin{itemize}
\item $A = PDP^{-1}$
\item Solution: $\mathbf{x}(t) = Pe^{Dt}P^{-1}\mathbf{x}_0$
\item Where $e^{Dt} = \text{diag}(e^{\lambda_1 t}, \ldots, e^{\lambda_n t})$
\end{itemize}
\end{keypoint}

\section{Solution Method Step-by-Step}

\begin{method}[Complete Solution Algorithm]
Given $\mathbf{x}' = A\mathbf{x}$ with $\mathbf{x}(0) = \mathbf{x}_0$:

\textbf{Step 1: Find Eigenvalues}
\begin{itemize}
\item Compute $\det(A - \lambda I) = 0$
\item For $2 \times 2$: $\det\begin{pmatrix} a_{11}-\lambda & a_{12} \\ a_{21} & a_{22}-\lambda \end{pmatrix} = 0$
\item Expand: $\lambda^2 - \text{tr}(A)\lambda + \det(A) = 0$
\end{itemize}

\textbf{Step 2: Find Eigenvectors}
\begin{itemize}
\item For each $\lambda_i$, solve $(A - \lambda_i I)\mathbf{v} = \mathbf{0}$
\item Row reduce to find null space
\item Choose convenient basis vector
\end{itemize}

\textbf{Step 3: Form General Solution}
\begin{itemize}
\item Write $\mathbf{x}(t) = \sum_{i=1}^n c_i e^{\lambda_i t}\mathbf{v}_i$
\end{itemize}

\textbf{Step 4: Apply Initial Conditions}
\begin{itemize}
\item Set $t = 0$: $\mathbf{x}_0 = \sum_{i=1}^n c_i \mathbf{v}_i$
\item Solve linear system for $c_1, \ldots, c_n$
\end{itemize}
\end{method}

\begin{example}[Complete 2×2 System]
Solve $\mathbf{x}' = \begin{pmatrix} 4 & 2 \\ 3 & -1 \end{pmatrix}\mathbf{x}$ with $\mathbf{x}(0) = \begin{pmatrix} 1 \\ 2 \end{pmatrix}$

\textbf{Solution:}
\begin{enumerate}
\item \textbf{Eigenvalues:}
\[\det(A - \lambda I) = \det\begin{pmatrix} 4-\lambda & 2 \\ 3 & -1-\lambda \end{pmatrix} = (4-\lambda)(-1-\lambda) - 6\]
\[= -4 - 4\lambda + \lambda + \lambda^2 - 6 = \lambda^2 - 3\lambda - 10 = 0\]
\[(\lambda - 5)(\lambda + 2) = 0 \implies \lambda_1 = 5, \lambda_2 = -2\]

\item \textbf{Eigenvectors:}

For $\lambda_1 = 5$:
\[(A - 5I)\mathbf{v} = \begin{pmatrix} -1 & 2 \\ 3 & -6 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\]
Row 1: $-v_1 + 2v_2 = 0 \implies v_1 = 2v_2$. Choose $v_2 = 1$: $\mathbf{v}_1 = \begin{pmatrix} 2 \\ 1 \end{pmatrix}$

For $\lambda_2 = -2$:
\[(A + 2I)\mathbf{v} = \begin{pmatrix} 6 & 2 \\ 3 & 1 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\]
Row 2: $3v_1 + v_2 = 0 \implies v_2 = -3v_1$. Choose $v_1 = 1$: $\mathbf{v}_2 = \begin{pmatrix} 1 \\ -3 \end{pmatrix}$

\item \textbf{General Solution:}
\[\mathbf{x}(t) = c_1 e^{5t}\begin{pmatrix} 2 \\ 1 \end{pmatrix} + c_2 e^{-2t}\begin{pmatrix} 1 \\ -3 \end{pmatrix}\]

\item \textbf{Initial Conditions:}
\[\begin{pmatrix} 1 \\ 2 \end{pmatrix} = c_1\begin{pmatrix} 2 \\ 1 \end{pmatrix} + c_2\begin{pmatrix} 1 \\ -3 \end{pmatrix}\]
System: $2c_1 + c_2 = 1$ and $c_1 - 3c_2 = 2$

From equation 2: $c_1 = 2 + 3c_2$. Substitute into equation 1:
\[2(2 + 3c_2) + c_2 = 1 \implies 4 + 7c_2 = 1 \implies c_2 = -\frac{3}{7}\]
\[c_1 = 2 + 3(-\frac{3}{7}) = 2 - \frac{9}{7} = \frac{5}{7}\]

\item \textbf{Final Solution:}
\[\mathbf{x}(t) = \frac{5}{7}e^{5t}\begin{pmatrix} 2 \\ 1 \end{pmatrix} - \frac{3}{7}e^{-2t}\begin{pmatrix} 1 \\ -3 \end{pmatrix}\]
\end{enumerate}
\end{example}

\begin{warning}
\textbf{Common Errors:}
\begin{itemize}
\item Forgetting that eigenvectors are determined up to scalar multiplication
\item Sign errors when computing $\det(A - \lambda I)$
\item Not verifying eigenvectors: always check $A\mathbf{v} = \lambda\mathbf{v}$
\item Arithmetic mistakes in the linear system for constants
\end{itemize}
\end{warning}

\begin{insight}
\textbf{Solution Behavior from Eigenvalues:}
\begin{itemize}
\item All $\lambda_i < 0$: Stable node (all solutions $\to \mathbf{0}$)
\item All $\lambda_i > 0$: Unstable node (all solutions grow)
\item Mixed signs: Saddle point
\item $\lambda_i = 0$: Non-isolated equilibrium (degenerate)
\end{itemize}
\end{insight}

\begin{examtip}
Prof. Ditkowski's exams typically include:
\begin{itemize}
\item One 2×2 system (always)
\item Possibly one 3×3 system
\item Initial value problems (60\% of system problems)
\item Questions about stability based on eigenvalues
\item Verification of solutions
\end{itemize}
\end{examtip}

\section{Phase Portrait Connection}

The eigenvalues and eigenvectors completely determine the phase portrait:
\begin{itemize}
\item Eigenvectors give the principal directions
\item Eigenvalues give the behavior along each direction
\item Trajectories are tangent to eigenvector directions at the origin
\end{itemize}

\begin{tikzpicture}
\begin{axis}[
    axis lines = center,
    xlabel = $x_1$,
    ylabel = $x_2$,
    xmin=-3, xmax=3,
    ymin=-3, ymax=3,
    title={Saddle Point: $\lambda_1 > 0, \lambda_2 < 0$}
]
% Eigenvector directions
\addplot[domain=-3:3, samples=2, thick, blue] {0.5*x};
\addplot[domain=-3:3, samples=2, thick, red] {-2*x};
% Sample trajectories
\addplot[domain=-2:2, samples=100, green] {sqrt(abs(x^2 - 1))};
\addplot[domain=-2:2, samples=100, green] {-sqrt(abs(x^2 - 1))};
\end{axis}
\end{tikzpicture}

\end{document}
```

## **Part 3: LaTeX Practice Problems**

```latex
\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, amsthm, enumitem, geometry}
\geometry{margin=1in}

\title{Lesson 30: Practice Problems - Distinct Eigenvalues}
\author{ODE 1 - Prof. Adi Ditkowski}
\date{}

\begin{document}
\maketitle

\section*{Part A: Eigenvalue/Eigenvector Computation}

\begin{enumerate}
\item Find all eigenvalues and eigenvectors of $A = \begin{pmatrix} 3 & 1 \\ 2 & 4 \end{pmatrix}$

\item Find all eigenvalues and eigenvectors of $A = \begin{pmatrix} 5 & -2 \\ 3 & -2 \end{pmatrix}$

\item Find all eigenvalues and eigenvectors of $A = \begin{pmatrix} 1 & 2 & 0 \\ 0 & 3 & 0 \\ 0 & 0 & -1 \end{pmatrix}$

\item Verify that $\mathbf{v} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}$ is an eigenvector of $A = \begin{pmatrix} 4 & 1 \\ 2 & 5 \end{pmatrix}$ and find the corresponding eigenvalue.

\item For the matrix $A = \begin{pmatrix} a & 1 \\ 0 & b \end{pmatrix}$, find conditions on $a$ and $b$ for distinct real eigenvalues.
\end{enumerate}

\section*{Part B: 2×2 Systems with Distinct Real Eigenvalues}

\begin{enumerate}[start=6]
\item Solve the system $\mathbf{x}' = \begin{pmatrix} 2 & 1 \\ 3 & 4 \end{pmatrix}\mathbf{x}$

\item Solve the IVP: $\mathbf{x}' = \begin{pmatrix} 1 & 2 \\ 2 & 1 \end{pmatrix}\mathbf{x}$, $\mathbf{x}(0) = \begin{pmatrix} 3 \\ 1 \end{pmatrix}$

\item Find the solution to $\mathbf{x}' = \begin{pmatrix} 4 & -2 \\ 1 & 1 \end{pmatrix}\mathbf{x}$ that satisfies $x_1(0) = 2, x_2(0) = -1$

\item Determine all solutions of $\mathbf{x}' = \begin{pmatrix} 3 & 4 \\ 1 & 3 \end{pmatrix}\mathbf{x}$ that remain bounded as $t \to \infty$

\item Find the fundamental matrix for $\mathbf{x}' = \begin{pmatrix} 5 & 3 \\ 1 & 3 \end{pmatrix}\mathbf{x}$
\end{enumerate}

\section*{Part C: 3×3 Systems with Distinct Eigenvalues}

\begin{enumerate}[start=11]
\item Solve: $\mathbf{x}' = \begin{pmatrix} 1 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 3 \end{pmatrix}\mathbf{x}$

\item Solve: $\mathbf{x}' = \begin{pmatrix} 2 & 1 & 1 \\ 0 & 3 & 1 \\ 0 & 0 & 4 \end{pmatrix}\mathbf{x}$

\item Find the general solution: $\mathbf{x}' = \begin{pmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 6 & -11 & 6 \end{pmatrix}\mathbf{x}$

\item Solve the IVP: $\mathbf{x}' = \begin{pmatrix} 1 & 0 & 1 \\ 0 & 2 & 0 \\ 1 & 0 & 1 \end{pmatrix}\mathbf{x}$, $\mathbf{x}(0) = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$

\item Find all equilibrium solutions and their stability for: $\mathbf{x}' = \begin{pmatrix} -1 & 0 & 0 \\ 0 & -2 & 0 \\ 0 & 0 & 3 \end{pmatrix}\mathbf{x}$
\end{enumerate}

\section*{Part D: Stability and Behavior Analysis}

\begin{enumerate}[start=16]
\item For what values of $k$ is the origin a stable equilibrium for $\mathbf{x}' = \begin{pmatrix} -1 & k \\ 0 & -2 \end{pmatrix}\mathbf{x}$?

\item Classify the equilibrium at the origin for $\mathbf{x}' = \begin{pmatrix} 3 & 5 \\ 1 & -1 \end{pmatrix}\mathbf{x}$

\item Find a system $\mathbf{x}' = A\mathbf{x}$ where all solutions approach the line $x_1 = x_2$ as $t \to \infty$

\item Determine the long-term behavior of solutions to $\mathbf{x}' = \begin{pmatrix} -3 & 2 \\ 1 & -2 \end{pmatrix}\mathbf{x}$

\item Show that if $A$ has all negative eigenvalues, then $\|\mathbf{x}(t)\| \to 0$ as $t \to \infty$
\end{enumerate}

\section*{Part E: Special Cases and Theory}

\begin{enumerate}[start=21]
\item Prove that if $A$ is symmetric, all eigenvalues are real

\item Show that $\text{tr}(A) = \sum \lambda_i$ and $\det(A) = \prod \lambda_i$

\item If $A$ has eigenvalues 2, 3, 5, what are the eigenvalues of $A^2$? Of $A^{-1}$?

\item Construct a 2×2 matrix with eigenvalues $\lambda_1 = 1, \lambda_2 = -2$ and eigenvectors $\mathbf{v}_1 = \begin{pmatrix} 1 \\ 1 \end{pmatrix}, \mathbf{v}_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}$

\item Find a 3×3 upper triangular matrix with eigenvalues 1, 2, 3 and determine its eigenvectors
\end{enumerate}

\section*{Part F: Application Problems}

\begin{enumerate}[start=26]
\item Two tanks contain salt solutions. Tank 1 has rate of change $x_1' = -0.1x_1 + 0.05x_2$ and Tank 2 has $x_2' = 0.1x_1 - 0.15x_2$. Find the salt amounts over time if initially $x_1(0) = 100, x_2(0) = 50$.

\item A predator-prey model gives $\mathbf{x}' = \begin{pmatrix} 2 & -1 \\ 1 & -1 \end{pmatrix}\mathbf{x}$ where $x_1$ is prey, $x_2$ is predator population. Analyze the long-term behavior.

\item Coupled springs lead to $\mathbf{x}' = \begin{pmatrix} 0 & 1 \\ -2 & 0 \end{pmatrix}\mathbf{x} + \begin{pmatrix} 0 & 0 \\ 0 & -3 \end{pmatrix}\mathbf{x}$. Find the general solution.

\item An electrical circuit gives $\mathbf{x}' = \begin{pmatrix} -R/L & -1/L \\ 1/C & 0 \end{pmatrix}\mathbf{x}$ with $R = 2, L = 1, C = 0.5$. Solve for the current and voltage.

\item \textbf{Challenge:} Show that the solution to $\mathbf{x}' = A\mathbf{x}$ can be written as $\mathbf{x}(t) = e^{At}\mathbf{x}_0$ and verify this for a diagonal matrix.
\end{enumerate}

\section*{Solutions and Hints}

\textbf{Problem 1:} $\lambda_1 = 5, \lambda_2 = 2$; $\mathbf{v}_1 = \begin{pmatrix} 1 \\ 2 \end{pmatrix}, \mathbf{v}_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}$

\textbf{Problem 7:} First find $\lambda_1 = 3, \lambda_2 = -1$. General solution involves $e^{3t}$ and $e^{-t}$ terms.

\textbf{Problem 11:} Diagonal matrix - eigenvectors are standard basis vectors.

\textbf{Problem 16:} Stable for all $k$ since both eigenvalues are negative regardless of $k$.

\textbf{Problem 22:} Use the fact that $\text{tr}(A) = \text{tr}(PDP^{-1}) = \text{tr}(D)$ where $D$ is diagonal with eigenvalues.

\textbf{Key Strategy:} Always verify your eigenvalues by checking that $\det(A - \lambda I) = 0$ and eigenvectors by confirming $A\mathbf{v} = \lambda\mathbf{v}$.

\end{document}
```

## **Part 4: NotebookLM Instructions**

### **How to Use These Materials with NotebookLM**

1. **Import Strategy:**
   - Upload the Audio Script as a text document
   - Import the Theory Document (compile LaTeX first, then upload PDF)
   - Add the Practice Problems as a separate document
   - Include any worked solutions you create

2. **Audio Generation Tips:**
   - Ask NotebookLM to create a "teaching dialogue" about eigenvalue methods
   - Request emphasis on the step-by-step algorithm
   - Have it explain common mistakes in a conversational way
   - Generate separate audio for 2×2 vs 3×3 examples

3. **Study Sequence:**
   - Start with the audio lesson for conceptual understanding
   - Work through Theory Document examples with paper and pencil
   - Attempt Practice Problems Part A (eigenvalue computation) first
   - Master 2×2 systems before moving to 3×3
   - Save Part F (applications) for after you're comfortable with the method

4. **Integration with Linear Algebra:**
   - Review eigenvalue/eigenvector computation from linear algebra
   - Practice matrix multiplication and inversion
   - Understand the geometric meaning of eigenvectors
   - Connect to diagonalization if you've studied it

5. **Connections to Previous Material:**
   - This extends the exponential solution from single equations to systems
   - The characteristic equation is like finding roots for the auxiliary equation
   - Superposition principle still applies (linear combinations of solutions)

6. **Exam Preparation Focus:**
   - Prof. Ditkowski ALWAYS includes at least one system with distinct eigenvalues
   - Show ALL steps in eigenvalue calculation
   - Verify eigenvectors by substitution
   - Practice the initial value problem setup
   - Be ready to classify equilibrium stability

7. **Common NotebookLM Queries to Try:**
   - "Walk me through finding eigenvalues for a 2×2 matrix"
   - "Why do eigenvectors give us solutions to the ODE?"
   - "Explain the connection between eigenvalues and solution behavior"
   - "Give me a practice problem with distinct negative eigenvalues"
   - "How do I know if I've found the right eigenvectors?"

8. **Time Management:**
   - Audio lesson: 20 minutes
   - Theory reading: 45 minutes
   - Working through examples: 1 hour
   - Practice problems Parts A-B: 1.5 hours
   - Practice problems Parts C-D: 1.5 hours
   - Review and consolidation: 30 minutes

9. **Self-Assessment Checkpoints:**
   - Can you find eigenvalues of any 2×2 matrix?
   - Can you find eigenvectors without looking at notes?
   - Can you write the general solution immediately after finding eigenvalues/eigenvectors?
   - Can you apply initial conditions to find specific solutions?
   - Can you predict solution behavior from eigenvalue signs?

10. **Links to Next Lessons:**
    - Lesson 31 will handle repeated eigenvalues (when you don't have enough eigenvectors)
    - Lesson 32 covers complex eigenvalues (oscillatory solutions)
    - Lesson 33 introduces the matrix exponential as a unified approach
    - This lesson is the foundation - master it before moving on!

---

**Lesson 30 complete. Request 'Generate Lesson 31' for the next lesson in Block 9.**
