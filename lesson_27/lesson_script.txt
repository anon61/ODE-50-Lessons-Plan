Episode 27: Fundamental Matrix Solutions - Construction**

Audio Lesson Script**

"Alright, now that we can convert any higher-order equation into a system, let's talk about THE most powerful tool for solving systems - the fundamental matrix. This is where linear algebra meets differential equations in the most beautiful way possible.

So basically, here's the big picture: for a system x' = A(t)x, we want to find a matrix Φ(t) whose columns are linearly independent solutions. This matrix literally contains ALL the information about your system's behavior. Once you have it, solving any initial value problem becomes just matrix multiplication. Let me show you why this is so powerful.

First, let's understand what a fundamental matrix actually is. If you have n linearly independent solutions x₁(t), x₂(t), ..., xₙ(t) to your system x' = A(t)x, then the fundamental matrix is simply:

Φ(t) = [x₁(t) | x₂(t) | ... | xₙ(t)]

where each solution is a column vector. Here's the key property - and this is CRUCIAL for Prof. Ditkowski's exams - the fundamental matrix satisfies:

Φ'(t) = A(t)Φ(t)

This means if you differentiate each column of Φ, you get A times that column. This is the defining property, and you'll often need to verify it on exams.

Now, here's where it gets really interesting. There's a special fundamental matrix called the principal fundamental matrix, which satisfies Φ(t₀) = I, the identity matrix. This one's particularly nice because the solution to the IVP with x(t₀) = x₀ becomes simply:

x(t) = Φ(t)x₀

No matrix inversion needed! But usually, we don't have this luxury. For a general fundamental matrix where Φ(t₀) ≠ I, the solution is:

x(t) = Φ(t)Φ(t₀)⁻¹x₀

Let me walk you through a concrete example. Consider the system:
x' = [0, 1; -2, -3]x

To find the fundamental matrix, we first need two independent solutions. Using eigenvalues (which we'll cover more later), we find λ₁ = -1 and λ₂ = -2, giving us:

x₁(t) = e^(-t)[1, -1]ᵀ and x₂(t) = e^(-2t)[1, -2]ᵀ

So our fundamental matrix is:
Φ(t) = [e^(-t), e^(-2t); -e^(-t), -2e^(-2t)]

Now here's a critical skill - verifying this is correct. We need to check Φ'(t) = AΦ(t):

Φ'(t) = [-e^(-t), -2e^(-2t); e^(-t), 4e^(-2t)]

And:
AΦ(t) = [0, 1; -2, -3][e^(-t), e^(-2t); -e^(-t), -2e^(-2t)] = [-e^(-t), -2e^(-2t); e^(-t), 4e^(-2t)]

They match! This verification step appears on EVERY exam.

Now, to solve an IVP, say x(0) = [3, -5]ᵀ. First, find Φ(0):
Φ(0) = [1, 1; -1, -2]

Then compute Φ(0)⁻¹. Here's a quick trick for 2×2 matrices:
For M = [a, b; c, d], we have M⁻¹ = (1/det(M))[d, -b; -c, a]

So Φ(0)⁻¹ = (1/(-1))[−2, -1; 1, 1] = [2, 1; -1, -1]

Therefore:
x(t) = Φ(t)Φ(0)⁻¹x₀ = [e^(-t), e^(-2t); -e^(-t), -2e^(-2t)][2, 1; -1, -1][3, -5]ᵀ

Working through the matrix multiplication:
Φ(0)⁻¹x₀ = [2, 1; -1, -1][3, -5]ᵀ = [1, 2]ᵀ

So: x(t) = [e^(-t), e^(-2t); -e^(-t), -2e^(-2t)][1, 2]ᵀ = [e^(-t) + 2e^(-2t), -e^(-t) - 4e^(-2t)]ᵀ

Here's a memory trick: think of the fundamental matrix as a 'solution container' - each column is a complete solution, and any linear combination of columns is also a solution. The coefficients in that linear combination? They're determined by your initial conditions!

Common mistakes to avoid:
1. Forgetting that columns must be linearly independent - always check the determinant!
2. Matrix multiplication order - it's Φ(t) times Φ(t₀)⁻¹, not the reverse
3. Not verifying Φ'(t) = A(t)Φ(t) - this costs easy points
4. Confusion between Φ(t) and Φ(t₀) - keep track of where you're evaluating

An advanced insight: the fundamental matrix is never singular! Its determinant, called the Wronskian, is never zero. We'll explore this more in the next lesson, but this means Φ(t)⁻¹ always exists.

For time-varying systems where A = A(t), the construction is conceptually the same but computationally harder. You still need n independent solutions, but finding them might require series methods or numerical techniques.

Here's what Prof. Ditkowski loves to test: given some solutions, construct Φ(t), verify it's fundamental, then use it to solve an IVP. Practice this three-step process until it's automatic. Also, he often asks about the relationship between different fundamental matrices - if Φ₁(t) and Φ₂(t) are both fundamental matrices for the same system, then Φ₂(t) = Φ₁(t)C for some constant invertible matrix C.

The fundamental matrix is truly fundamental - it encodes everything about your system's solution space. Master this concept, and systems of ODEs become manageable!"